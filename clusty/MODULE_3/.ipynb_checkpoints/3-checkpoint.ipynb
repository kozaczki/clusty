{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5516929a",
   "metadata": {},
   "source": [
    "# Module 3\n",
    "\n",
    "\n",
    "**Function:** \n",
    "\n",
    "a) Distributes clusters identified in module 2_2 into individual structures\n",
    "\n",
    "b) Identifies clusters in individual structures.\n",
    "\n",
    "**Flow:** Using primes products identifies structures with clusters and save\n",
    "them in distribution matrix. Then using Leiden's algorith identifies clusters in individual structures\n",
    "\n",
    "**Input:** population of structures (filename format: cf_XXXXXX.coords.csv, XXXXXX - structure id completed to six zeros), list of primes, primes products, list of clusters\n",
    "\n",
    "**Output:** distribution matrix, list of clusters in individual structures\n",
    "\n",
    "**Usage:** Provide path to csv file with variables and run the notebook\n",
    "\n",
    "\n",
    "<img src=\"3.png\" alt=\"drawing\"  width=\"750\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2168aad",
   "metadata": {},
   "source": [
    "## path to parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER PATH TO CSV FILE WITH PARAMETERS ###\n",
    "path_to_parameters = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dada683",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c731a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import umap\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import cdlib\n",
    "from cdlib import algorithms\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import ray\n",
    "from scipy.sparse import csr_matrix\n",
    "import csv\n",
    "\n",
    "import pickle\n",
    "\n",
    "import scipy.spatial\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5258a3ef",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_pickle(path):\n",
    "    file_to_read = open(path, \"rb\")\n",
    "    loaded_object = pickle.load(file_to_read)\n",
    "    file_to_read.close()\n",
    "    return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf819c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicies_for_cluster(cluster,product,primes):\n",
    "    \"\"\"\n",
    "    gets structures in which given cluster occurs\n",
    "    \"\"\"\n",
    "    # turn cluster beads to indicies\n",
    "    cluster_indexes = [i - 1 for i in cluster]\n",
    "    # turn indicies to primes product\n",
    "    cluster_primes_product = np.prod(primes[cluster_indexes])\n",
    "    # check occurence\n",
    "    indicies = (np.where(product % cluster_primes_product == 0)[0])\n",
    "    \n",
    "    return indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distributions_for_population(clusters_list,product_full,primes):\n",
    "    clusters_in_structures = np.zeros((number_of_structures,number_of_beads_per_structure))\n",
    "    for pair in clusters_list:\n",
    "        clusters = pair[1]\n",
    "        if len(clusters) > 0:\n",
    "            bead = pair[0]\n",
    "            bead_index = bead - 1\n",
    "            for cl in clusters:\n",
    "                str_indicies = get_indicies_for_cluster(cl,product_full[:,bead_index],primes)\n",
    "                for str_index in str_indicies:\n",
    "                    for b in cl:\n",
    "                        clusters_in_structures[str_index,b-1] = 1\n",
    "                        \n",
    "    return clusters_in_structures   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0287e",
   "metadata": {},
   "source": [
    "## load parameters, build folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f15fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paramaters from csv file \n",
    "\n",
    "# parse csv file with parameters\n",
    "paramaters = []\n",
    "with open(path_to_parameters, 'rt') as csvfile:\n",
    "    reader = csv.reader(csvfile, skipinitialspace=True)\n",
    "    paramaters.append(list(reader))\n",
    "    csvfile.close()\n",
    "\n",
    "#list with setup parameters\n",
    "params = paramaters[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign setup variebles from params\n",
    "\n",
    "home = params[0][1]\n",
    "number_of_structures = int(params[1][1])\n",
    "number_of_beads_per_structure = int(params[2][1])\n",
    "fraction = float(params[3][1])\n",
    "structures_fraction = number_of_structures * fraction\n",
    "cores = int(params[4][1])\n",
    "dataset_name =  params[6][1]\n",
    "dataset_folder =  params[7][1]\n",
    "a_type = params[8][1]\n",
    "chromosomal_borders_file = params[9][1]\n",
    "primes_file = params[10][1]\n",
    "cutoff = fraction = float(params[11][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee498d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose analysis name\n",
    "\n",
    "if a_type == 'fixed':\n",
    "    r_factor  = float(params[5][1])\n",
    "    analysis_name = dataset_name + '_fixed_radius_' + str(r_factor)\n",
    "\n",
    "if a_type == 'neighbours':\n",
    "    k  = int(params[5][1])\n",
    "    analysis_name = dataset_name + '_neighbours_' + str(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c84367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle dataset_name depending on analysis_type\n",
    "\n",
    "if a_type == 'fixed':\n",
    "    r_factor  = float(params[5][1])\n",
    "    dataset_name = dataset_name + '_fixed_radius_' + str(r_factor)\n",
    "\n",
    "if a_type == 'neighbours':\n",
    "    k  = int(params[5][1])\n",
    "    dataset_name = dataset_name + '_neighbours_' + str(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a91ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print setup variables for manual inspection\n",
    "print(\"\")\n",
    "print(\"Running cluster detection in structures\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"dataset name: \" + dataset_name)\n",
    "\n",
    "print(\"loaded setup variables\")\n",
    "print(\"\")\n",
    "print(\"home folder: \" + home)\n",
    "print(\"dataset folder: \" + dataset_folder)\n",
    "print(\"dataset name: \" + dataset_name)\n",
    "print(\"number of structures: \" + str(number_of_structures))\n",
    "print(\"number of beads per structure: \" + str(number_of_beads_per_structure))\n",
    "print(\"fraction: \" + str(fraction))\n",
    "\n",
    "if a_type == \"fixed\":\n",
    "    print(\"radius factor: \" + str(r_factor))\n",
    "if a_type == 'neighbours':\n",
    "    print(\"k: \" + str(k))\n",
    "\n",
    "print(\"cores: \" + str(cores))\n",
    "print(\"\")\n",
    "print(\"cutoff: \" + str(cutoff))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598584dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "helper_folder = os.path.join(home,'helper_data')\n",
    "\n",
    "primes_array = np.load(os.path.join(helper_folder,primes_file),allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c58fc",
   "metadata": {},
   "source": [
    "## distrubute clustered beads to structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD clusters\n",
    "\n",
    "clusters_path = os.path.join(home,'runs',analysis_name,'results' , analysis_name + '_clusters_simple_filtered')\n",
    "clusters_list = read_from_pickle(clusters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load product\n",
    "\n",
    "product_full_path = os.path.join(home,'runs',analysis_name,'intermediate', 'products','product_full.npy')\n",
    "product_full = np.load(product_full_path,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify cluster\n",
    "\n",
    "start_distributing = time.time()\n",
    "\n",
    "distro = get_distributions_for_population(clusters_list,product_full,primes_array)\n",
    "\n",
    "print(str(time.time() - start_distributing))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404828b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (5,5))\n",
    "ax.hist(distro.sum(axis=1))\n",
    "fig.savefig(os.path.join(home,'runs',analysis_name,'figures',analysis_name + '_distro_hist.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e945e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "distro_full_path = os.path.join(home,'runs',analysis_name,'intermediate',analysis_name + '_distro_matrix')\n",
    "np.save(distro_full_path,distro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00532c7d",
   "metadata": {},
   "source": [
    "## clustered beads quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a399d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d251308",
   "metadata": {},
   "source": [
    "## identify clusters in structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper funcitons\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ba772",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def build_communities(num,clusters_array,cutoff):\n",
    "    file = os.path.join(dataset_folder,'cf_' + str(num).zfill(6) + '.coords.csv')\n",
    "    csv = np.genfromtxt(file,delimiter=',')\n",
    "    coordinates = csv[:,:3]\n",
    "    clustered = np.where(clusters_array == 1)[0]\n",
    "    if len(clustered) == 0:\n",
    "        return num, []\n",
    "    coords_for_communities = coordinates[clustered]\n",
    "    distances = scipy.spatial.distance.pdist(coords_for_communities)\n",
    "    distances_matrix = scipy.spatial.distance.squareform(distances)\n",
    "    adj_matrix = np.zeros((len(clustered),len(clustered)))\n",
    "    for i in range(len(clustered)):\n",
    "        for j in range(len(clustered)):\n",
    "            if distances_matrix[i,j] <= cutoff:\n",
    "                adj_matrix[i,j] = 1\n",
    "    g = nx.from_numpy_matrix(adj_matrix)\n",
    "    eset = [(u, v) for (u, v, d) in g.edges(data=True)] # get list of edges from graph\n",
    "    weights = [d['weight'] for (u, v, d) in g.edges(data=True)] # get list of weights from edges\n",
    "    # find communities\n",
    "    # in this example we use the Leiden algorithm\n",
    "    leiden_coms = algorithms.leiden(g,weights=weights) # check if the algo is stochastic, in that case set rnd generator    \n",
    "    leiden_coms.communities # a list of lists of nodes\n",
    "    communities_in_str = []\n",
    "    for community in leiden_coms.communities:\n",
    "        communities_in_str.append(clustered[community])\n",
    "    return num,communities_in_str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list\n",
    "list_path = os.path.join(home,'runs',analysis_name,'intermediate',analysis_name + '_sparse_neighbour_matrices_list')\n",
    "list_of_str = read_from_pickle(list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change list_of_str to lighter\n",
    "list_str = [i[1] for i in list_of_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through matrix and structures:\n",
    "\n",
    "# begin multiprocessing\n",
    "\n",
    "ray.init()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = []\n",
    "\n",
    "path_to_store = os.path.join(home,'runs',analysis_name,'intermediate',analysis_name + '_clusters_in_structures')\n",
    "\n",
    "# process bead by bead\n",
    "\n",
    "#for chunk in chunker(range(number_of_beads_per_structure),cores):\n",
    "\n",
    "\n",
    "for chunk in chunker(range(number_of_structures),cores):\n",
    "    communities = [build_communities.remote(list_str[i],distro[i],cutoff) for i in chunk]\n",
    "    partial_results = ray.get(communities)\n",
    "    results.append(partial_results)\n",
    "\n",
    "    file_to_store = open(path_to_store, \"wb\")\n",
    "    pickle.dump(results, file_to_store)\n",
    "\n",
    "    file_to_store.close()\n",
    "\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect clusters in one list\n",
    "chained_results = list(itertools.chain(*results))\n",
    "cluster_sizes = []\n",
    "for i in chained_results:\n",
    "    for j in i[1]:\n",
    "        cluster_sizes.append(len(j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cluster_sizes,bins=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
