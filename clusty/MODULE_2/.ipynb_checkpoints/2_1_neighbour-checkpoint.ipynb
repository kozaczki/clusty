{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2_1 -  nearest neighbours\n",
    "\n",
    "**Function:** Prepares intermediate files used by module 2_2 for cluster identification.\n",
    "\n",
    "**Flow:** For each structure and for each bead it extracts bead's neighbourhood, here defined as k nearrest beads.\n",
    "\n",
    "**Input:** population of structures (filename format: cf_XXXXXX.coords.csv, XXXXXX - structure id completed to six zeros), list of primes\n",
    "\n",
    "**Output:** product matrix (full and per bead), frequencies matrix (pairwise cooucurence), binary matrix (pairwise coocurence above certain treshold)\n",
    "\n",
    "**Usage:** Provide path to csv file with variables and run the notebook\n",
    "\n",
    "\n",
    "<img src=\"2_1_neighbours_jup.png\" width=800  align=\"left\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## path to parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER PATH TO CSV FILE WITH PARAMETERS ###\n",
    "path_to_parameters = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from scipy import sparse\n",
    "import ray\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    \"\"\"\n",
    "    input: sequence (eg. list)\n",
    "    ouptput: sequence divided in chunks\n",
    "    parameters: size: determines the length of the chunk\n",
    "\n",
    "    \"\"\"\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_file_to_distances_matrix(structure_file):\n",
    "\n",
    "    \"\"\"\n",
    "    input: csv file with coordinates\n",
    "    output: distance matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # load csv\n",
    "    csv = np.genfromtxt(structure_file,delimiter=',')\n",
    "\n",
    "    # limit to first theree columns\n",
    "    coordinates = csv[:,:3]\n",
    "\n",
    "    # calculate all distances\n",
    "    distances = scipy.spatial.distance.pdist(coordinates)\n",
    "\n",
    "    # convert distance matrix to square form\n",
    "    distances_matrix = scipy.spatial.distance.squareform(distances)\n",
    "\n",
    "    return distances_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def structure_to_neigbours(structure_file,neighbours,number):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes a csv file of a single structure and returns\n",
    "    matrix of k-nearrest beads for each bead as sparse matrix, together with csv id number\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # read csv and return a matrix with pairwise distances\n",
    "\n",
    "    dist_mat = structure_file_to_distances_matrix(structure_file)\n",
    "    \n",
    "    # sort according to distances\n",
    "    \n",
    "    distances_matrix_sorted = np.sort(dist_mat, axis = 1)\n",
    "    \n",
    "    # argsort according to distances, returns indexes, + 1 to obtain beads ids\n",
    "    \n",
    "    distances_matrix_sorted_args = np.argsort(dist_mat, axis = 1) + 1 \n",
    "    \n",
    "    # first dimension should be equal to number of beads in structure\n",
    "    \n",
    "    first_dimension = dist_mat.shape[0]\n",
    "    \n",
    "    # second dimension is the k parameter\n",
    "    \n",
    "    second_dimension = neighbours\n",
    "    \n",
    "    # trim sorted beads ids -> [all beads, first neighbour:k-th neighbours]\n",
    "    \n",
    "    neighbours = distances_matrix_sorted_args[:,1:second_dimension+1]\n",
    "    \n",
    "    # convert to ushort - save mem\n",
    "    \n",
    "    neighbours = neighbours.astype(np.ushort)\n",
    "    \n",
    "    # covert to sparse form\n",
    "    \n",
    "    sparse_neighbours = sparse.csr_matrix(neighbours)\n",
    "\n",
    "    return sparse_neighbours,number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_file_name(number):\n",
    "    name = 'cf_' + number.zfill(6) + '.coords.csv'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading parameters, building folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start time to trace execution time\n",
    "\n",
    "start_all = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paramaters from csv file \n",
    "\n",
    "# parse csv file with parameters\n",
    "paramaters = []\n",
    "with open(path_to_parameters, 'rt') as csvfile:\n",
    "    reader = csv.reader(csvfile, skipinitialspace=True)\n",
    "    paramaters.append(list(reader))\n",
    "    csvfile.close()\n",
    "\n",
    "#list with setup parameters\n",
    "params = paramaters[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if correct mode\n",
    "\n",
    "mode = params[8][1]\n",
    "\n",
    "if mode == 'fixed':\n",
    "    print(\"incorrect mode - use either neighbours mode or 3_1_fixed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign setup variebles from params\n",
    "\n",
    "home = params[0][1]\n",
    "number_of_structures = int(params[1][1])\n",
    "number_of_beads_per_structure = int(params[2][1])\n",
    "fraction = float(params[3][1])\n",
    "structures_fraction = number_of_structures * fraction\n",
    "cores = int(params[4][1])\n",
    "k  = int(params[5][1])\n",
    "dataset_name =  params[6][1]\n",
    "\n",
    "dataset_folder =  params[7][1]\n",
    "chromosomal_borders_file = params[9][1]\n",
    "primes_file = params[10][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose analysis name\n",
    "\n",
    "analysis_name = dataset_name + '_neighbours_' + str(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print setup variables for manual inspection\n",
    "print(\"\")\n",
    "print('preprocessing structures for ' + str(k) +' the nearrest neighbours')\n",
    "print(\"\")\n",
    "\n",
    "print(\"loaded setup variables\")\n",
    "print(\"\")\n",
    "print(\"home folder: \" + home)\n",
    "print(\"dataset folder: \" + dataset_folder)\n",
    "print(\"dataset name: \" + dataset_name)\n",
    "print(\"number of structures: \" + str(number_of_structures))\n",
    "print(\"number of beads per structure: \" + str(number_of_beads_per_structure))\n",
    "print(\"fraction: \" + str(fraction))\n",
    "print(\"k: \" + str(k))\n",
    "print(\"cores: \" + str(cores))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process helper data\n",
    "\n",
    "# build paths for helper data files\n",
    "\n",
    "helper_folder = os.path.join(home,'helper_data')\n",
    "\n",
    "    # primes array\n",
    "\n",
    "primes_array = np.load(os.path.join(helper_folder,primes_file),allow_pickle=True)\n",
    "\n",
    "    # chromosomal borders array\n",
    "\n",
    "chromosomal_borders = np.load(os.path.join(helper_folder,chromosomal_borders_file))\n",
    "\n",
    "    # transform borders matrix into 1D\n",
    "\n",
    "borders_array = np.unique(chromosomal_borders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build folders structure\n",
    "\n",
    "run_folder = os.path.join(home,'runs',analysis_name)\n",
    "intermediate_files_folder = os.path.join(run_folder,'intermediate')\n",
    "product_folder = os.path.join(intermediate_files_folder,\"products\")\n",
    "results_folder = os.path.join(run_folder,'results')\n",
    "figures_folder = os.path.join(run_folder,'figures')\n",
    "\n",
    "print(\"building folders structure for the run\")\n",
    "\n",
    "\n",
    "folders = [run_folder,intermediate_files_folder,product_folder,results_folder,figures_folder]\n",
    "\n",
    "for folder in folders:\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "        print(\"Directory \" , folder ,  \" Created \")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , folder ,  \" already exists\")\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start multiprocessing \n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process structures in batch:\n",
    "# csv -> distances -> k neighbours\n",
    "# and prepare list of tuples (neighbours matrix,id of structure)\n",
    "# should be ordered by ids\n",
    "\n",
    "files = os.listdir(dataset_folder)\n",
    "\n",
    "sparse_matrices = []\n",
    "\n",
    "for numbers_chunk in chunker(list(range(1,(number_of_structures+1))),cores):\n",
    "    ids = [structure_to_neigbours.remote(os.path.join(dataset_folder,prepare_file_name(str(number))),k,number) for number in numbers_chunk]\n",
    "    partial_results = ray.get(ids)\n",
    "    sparse_matrices.append(partial_results)\n",
    "    \n",
    "\n",
    "# put all matrices in one list\n",
    "\n",
    "final_list = sparse_matrices[0]\n",
    "for i in range(1,len(sparse_matrices)):\n",
    "    final_list = list(itertools.chain(final_list,sparse_matrices[i]))\n",
    "\n",
    "# print length of the matrices list\n",
    "\n",
    "print(\"Final list of neighbourhoods contains \" + str(len(final_list)) + \" elements\\n\")\n",
    "\n",
    "print(time.time() - start_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matrices -> intermediate/dataset_name/_sparse_neighbour_matrices_list\n",
    "\n",
    "file_to_store = open(os.path.join(intermediate_files_folder,analysis_name + '_sparse_neighbour_matrices_list') , \"wb\")\n",
    "pickle.dump(final_list, file_to_store)\n",
    "file_to_store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build one matrix containing all neighbourhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build matrix with neighbourhoods - all beads across all structures -> to be used for products\n",
    "# values in  neigbhours correspond to beads ids\n",
    "# keeps ids\n",
    "\n",
    "neigbhours = np.zeros((number_of_structures,number_of_beads_per_structure,k),dtype = int)\n",
    "\n",
    "# iterate over list of neigbours in structures\n",
    "for x in range(number_of_structures):\n",
    "    \n",
    "    # pick neighbours from list\n",
    "    structure_x = final_list[x][0]\n",
    "    # convert to dense form\n",
    "    structure_x_dense = sparse.csc_matrix.todense(structure_x)\n",
    "    # put in the neighbours matrix\n",
    "    neigbhours[x] = structure_x_dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare frequency matrix and binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes to indexes\n",
    "\n",
    "frequencies = np.zeros((number_of_beads_per_structure,number_of_beads_per_structure),dtype = int)\n",
    "\n",
    "# prepare coocurence matrix based on neigbhours matrix\n",
    "\n",
    "#iterate over beads dimension in neighbourhood matrix\n",
    "for x in range(number_of_beads_per_structure):\n",
    "\n",
    "    # get neighbourhood for bead x across all structures\n",
    "    bead_x_all_structures = neigbhours[:,x,:]\n",
    "    # get occurences of beads in bead x neighbourhood across all structures\n",
    "    val, counts = np.unique(bead_x_all_structures,return_counts=True)\n",
    "\n",
    "    # assign values to frequencies matrix\n",
    "    for i in range(len(val)):\n",
    "        if val[i] != 0:\n",
    "            frequencies[x,val[i]-1] = counts[i] # i - 1 becuese in neigbhours matrix values are correspondingto bead ids, whereas in frequencies it goes by indexes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary matrix <- used in module 3_2 to identify clusters, generate from frequencies matrix, if values is above treshold binary matirx get 1, otherwise 0\n",
    "\n",
    "binary = np.zeros((number_of_beads_per_structure,number_of_beads_per_structure),dtype = int)\n",
    "for x in range(number_of_beads_per_structure):\n",
    "    for y in range(number_of_beads_per_structure):\n",
    "        if frequencies[x,y] >= structures_fraction:\n",
    "            binary[x,y]=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert neighbourhoods to products of primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get product\n",
    "\n",
    "primes = primes_array\n",
    "\n",
    "# bead numbers         [1,2,3,4,5]\n",
    "# primes_array indexes [0,1,2,3,4]\n",
    "# primes               [2,3,5,7,11]\n",
    "\n",
    "\n",
    "# matrix to hold products\n",
    "\n",
    "products = np.zeros((number_of_structures,number_of_beads_per_structure),dtype = object)\n",
    "\n",
    "\n",
    "# iterate over structures\n",
    "\n",
    "\n",
    "\n",
    "for x in range(len(final_list)): # structures\n",
    "\n",
    "    # load structure x\n",
    "    structure_x = final_list[x][0]\n",
    "    # convert from sparse to dense\n",
    "    structure_x_dense = sparse.csc_matrix.todense(structure_x)\n",
    "    # get shape for conversion to primes\n",
    "    shape = np.shape(structure_x_dense)\n",
    "    second_dimension = shape[1]\n",
    "    # matirx for primes\n",
    "    beads_as_primes = np.zeros((number_of_beads_per_structure,second_dimension),dtype = object)\n",
    "\n",
    "    # for each bead\n",
    "    for i in range(number_of_beads_per_structure):\n",
    "        # for each of the neighbours\n",
    "        for j in range(second_dimension):\n",
    "            bead = structure_x_dense[i,j]\n",
    "            # if 0 than no neigbour\n",
    "            if bead == 0:\n",
    "                # 1 multiplying by 1 will not change product\n",
    "                beads_as_primes[i,j] = 1\n",
    "            else:\n",
    "                beads_as_primes[i,j] = primes[bead - 1] # as below\n",
    "                # bead numbers         [1,2,3,4,5]\n",
    "                # primes_array indexes [0,1,2,3,4]\n",
    "                # primes               [2,3,5,7,11]\n",
    "\n",
    "    # obtain neighbourhoods as products\n",
    "    product_str_x = np.prod(beads_as_primes,axis = 1)\n",
    "    # assign to products matrix\n",
    "    products[x] = product_str_x\n",
    "    if x%50 == 0:\n",
    "        print(x)\n",
    "    \n",
    "\n",
    "# save full product\n",
    "\n",
    "np.save(product_folder + '/product_full', products)\n",
    "\n",
    "print(\"full product saved\")\n",
    "\n",
    "# save products by beads (for module 3_2)\n",
    "for b in range(number_of_beads_per_structure):\n",
    "    prod_bead = products[:,b]\n",
    "    np.save(product_folder + '/prod_' + str(b+1),prod_bead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare figurs and save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare figure for frequencies\n",
    "\n",
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(frequencies)\n",
    "fig.savefig(os.path.join(figures_folder,analysis_name + '_frequencies.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare figure for binaryy\n",
    "\n",
    "sns.set_theme()\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "ax = sns.heatmap(binary)\n",
    "fig.savefig(os.path.join(figures_folder,analysis_name + '_binary.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SAVE FILES frequencies and binaries\n",
    "\n",
    "np.save(os.path.join(intermediate_files_folder,analysis_name + '_binary'),binary)\n",
    "np.save(os.path.join(intermediate_files_folder,analysis_name + '_frequencies'),frequencies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
